{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# OpenCV - 이미지 읽기, 쓰기 및 표시하기 (1)\n",
    "\n",
    "import cv2\n",
    "\n",
    "def handle_image():\n",
    "    imgfile = 'images/sample.png'\n",
    "    img = cv2.imread(imgfile, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    cv2.imshow('image', img)\n",
    "    \n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    handle_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OpenCV - 이미지 읽기, 쓰기 및 표시하기 (2)\n",
    "\n",
    "import cv2\n",
    "\n",
    "def handle_image():\n",
    "    imgfile = 'images/sample.png'\n",
    "    img = cv2.imread(imgfile, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    cv2.namedWindow('image', cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow('image', img)\n",
    "    k = cv2.waitKey(0)\n",
    "    # wait for ESC key to exit\n",
    "    if k == 27:\n",
    "        cv2.destroyAllWindows()\n",
    "        cv2.waitKey(1)\n",
    "    # wait for 's' key to save and exit\n",
    "    elif k == ord('s'):\n",
    "        cv2.imwrite('grayImage.png', img)\n",
    "        cv2.destroyAllWindows()\n",
    "        cv2.waitKey(1)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    handle_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# OpenCV - 도형 외곽 추출하기 (1)\n",
    "\n",
    "import cv2\n",
    "\n",
    "def contour():\n",
    "    imgfile = 'images/sample3.jpg'\n",
    "    img = cv2.imread(imgfile)\n",
    "    imgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    edge = cv2.Canny(imgray, 100, 200)\n",
    "    contours, hierarchy = cv2.findContours(edge, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    cv2.imshow('edge', edge)\n",
    "    cv2.drawContours(img, contours, -1, (0, 255, 0), 1)\n",
    "    cv2.imshow('Contour', img)\n",
    "    \n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    contour() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# OpenCV - 도형 외곽 추출하기 (2)\n",
    "\n",
    "import cv2\n",
    "\n",
    "def contour_approx():\n",
    "    imgfile = 'images/sample6.png'\n",
    "    img = cv2.imread(imgfile)\n",
    "    img2 = img.copy()\n",
    "    imgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    edge = cv2.Canny(imgray, 100, 200)\n",
    "    contours, hierarchy = cv2.findContours(edge, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    cnt = contours[0]\n",
    "    cv2.drawContours(img, [cnt], 0, (0, 255, 0), 3)\n",
    "    \n",
    "    epsilon = 0.1 * cv2.arcLength(cnt, True)\n",
    "    \n",
    "    approx = cv2.approxPolyDP(cnt, epsilon, True)\n",
    "    \n",
    "    cv2.drawContours(img2, [approx], 0, (0, 255, 0), 3)\n",
    "    \n",
    "    cv2.imshow('Contour', img)\n",
    "    cv2.imshow('Approx', img2)\n",
    "    \n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    contour_approx() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# OpenCV - 투영변환 구현하기 (1)\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def warp_affine():\n",
    "    img = cv2.imread('images/sample4.png')\n",
    "    \n",
    "    pts1 = np.float32([[50, 50], [200, 50], [20, 200]])\n",
    "    pts2 = np.float32([[70, 100], [220, 50], [150, 250]])\n",
    "    \n",
    "    M = cv2.getAffineTransform(pts1, pts2)\n",
    "    \n",
    "    result = cv2.warpAffine(img, M, (350, 300))\n",
    "    \n",
    "    cv2.imshow('original', img)\n",
    "    cv2.imshow('Affine Transform', result)\n",
    "    \n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    warp_affine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# OpenCV - 투영변환 구현하기 (2)\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def warp_perspective():\n",
    "    img = cv2.imread('images/sample5.jpg')\n",
    "    \n",
    "    topLeft = [127, 157]\n",
    "    topRight = [448, 152]\n",
    "    bottomRight = [579, 526]\n",
    "    bottomLeft = [54, 549]\n",
    "    \n",
    "    pts1 = np.float32([topLeft, topRight, bottomRight, bottomLeft])\n",
    "    \n",
    "    w1 = abs(bottomRight[0] - bottomLeft[0])\n",
    "    w2 = abs(topRight[0] - topLeft[0])\n",
    "    h1 = abs(topRight[1] - bottomRight[1])\n",
    "    h2 = abs(topLeft[1] - bottomLeft[1])\n",
    "    minWidth = min([w1, w2])\n",
    "    minHeight = min([h1, h2])\n",
    "    \n",
    "    pts2 = np.float32([[0,0], [minWidth-1,0], \n",
    "                      [minWidth-1,minHeight-1], [0,minHeight-1]])\n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "    \n",
    "    result = cv2.warpPerspective(img, M, (int(minWidth), int(minHeight)))\n",
    "    \n",
    "    cv2.imshow('original', img)\n",
    "    cv2.imshow('Warp Transform', result)\n",
    "    \n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    warp_perspective()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# OpenCV - 스캔한 듯한 효과 주기 (1)\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Callback Function for Trackbar (but do not any work)\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "def global_threshold():\n",
    "    imgfile = 'images/document.jpg'\n",
    "    img = cv2.imread(imgfile, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Resize image\n",
    "    r = 600.0 / img.shape[0]\n",
    "    dim = (int(img.shape[1] * r), 600)\n",
    "    img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    WindowName = \"Window\"\n",
    "    TrackbarName = \"Threshold\"\n",
    "    \n",
    "    # Make Window and Trackbar\n",
    "    cv2.namedWindow(WindowName)\n",
    "    cv2.createTrackbar(TrackbarName, WindowName, 50, 255, nothing)\n",
    "    \n",
    "    # Allocate destination image\n",
    "    Threshold = np.zeros(img.shape, np.uint8)\n",
    "    \n",
    "    # Loop for get trackbar pos and process it\n",
    "    while True:\n",
    "        # Get position in trackbar\n",
    "        TrackbarPos = cv2.getTrackbarPos(TrackbarName, WindowName)\n",
    "        # Apply threshold\n",
    "        cv2.threshold(img, TrackbarPos, 255, cv2.THRESH_BINARY, Threshold)\n",
    "        # Show in window\n",
    "        cv2.imshow(WindowName, Threshold)\n",
    "        \n",
    "        # wait for ESC key to exit\n",
    "        k = cv2.waitKey(0)\n",
    "        if k == 27:\n",
    "            cv2.destroyAllWindows()\n",
    "            cv2.waitKey(1)\n",
    "            break\n",
    "    return\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    global_threshold() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# OpenCV - 스캔한 듯한 효과 주기 (2)\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def adaptive_threshold():\n",
    "    imgfile = 'images/document.jpg'\n",
    "    img = cv2.imread(imgfile, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Resize image\n",
    "    r = 600.0 / img.shape[0]\n",
    "    dim = (int(img.shape[1] * r), 600)\n",
    "    img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    # Blur image and apply adaptive threshold\n",
    "    blur = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "    result_without_blur = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 21, 10)\n",
    "    result_with_blur = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 21, 10)\n",
    "    cv2.imshow('Without Blur', result_without_blur)\n",
    "    cv2.imshow('With Blur', result_with_blur)\n",
    "    \n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    adaptive_threshold() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1: Edge Detection\n",
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 4: Apply Adaptive Threshold\n"
     ]
    }
   ],
   "source": [
    "# 명함인식 구현하기\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def order_points(pts):\n",
    "    # initialzie a list of coordinates that will be ordered\n",
    "    # such that the first entry in the list is the top-left,\n",
    "    # the second entry is the top-right, the third is the\n",
    "    # bottom-right, and the fourth is the bottom-left\n",
    "    rect = np.zeros((4, 2), dtype = \"float32\")\n",
    "\n",
    "    # the top-left point will have the smallest sum, whereas\n",
    "    # the bottom-right point will have the largest sum\n",
    "    s = pts.sum(axis = 1)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "\n",
    "    # now, compute the difference between the points, the\n",
    "    # top-right point will have the smallest difference,\n",
    "    # whereas the bottom-left will have the largest difference\n",
    "    diff = np.diff(pts, axis = 1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "\n",
    "    # return the ordered coordinates\n",
    "    return rect\n",
    "\n",
    "def auto_scan_image():\n",
    "    # load the image and compute the ratio of the old height\n",
    "    # to the new height, clone it, and resize it\n",
    "    # document.jpg ~ docuemnt7.jpg\n",
    "    image = cv2.imread('images/document.jpg')\n",
    "    orig = image.copy()\n",
    "    r = 800.0 / image.shape[0]\n",
    "    dim = (int(image.shape[1] * r), 800)\n",
    "    image = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "    # convert the image to grayscale, and find edges\n",
    "    # in the image\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    edged = cv2.Canny(gray, 75, 200)\n",
    "\n",
    "    # show the original image and the edge detected image\n",
    "    print \"STEP 1: Edge Detection\"\n",
    "    cv2.imshow(\"Image\", image)\n",
    "    cv2.imshow(\"Edged\", edged)\n",
    "    \n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "    # find the contours in the edged image, keeping only the\n",
    "    # largest ones, and initialize the screen contour\n",
    "    (cnts, _) = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = sorted(cnts, key = cv2.contourArea, reverse = True)[:5]\n",
    "\n",
    "    # loop over the contours\n",
    "    for c in cnts:\n",
    "        # approximate the contour\n",
    "        peri = cv2.arcLength(c, True)\n",
    "        approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "\n",
    "        # if our approximated contour has four points, then we\n",
    "        # can assume that we have found our screen\n",
    "        if len(approx) == 4:\n",
    "            screenCnt = approx\n",
    "            break\n",
    "\n",
    "    # show the contour (outline) of the piece of paper\n",
    "    print \"STEP 2: Find contours of paper\"\n",
    "    cv2.drawContours(image, [screenCnt], -1, (0, 255, 0), 2)\n",
    "    cv2.imshow(\"Outline\", image)\n",
    "    \n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "    # apply the four point transform to obtain a top-down\n",
    "    # view of the original image\n",
    "    rect = order_points(screenCnt.reshape(4, 2) / r)\n",
    "    (topLeft, topRight, bottomRight, bottomLeft) = rect\n",
    "    \n",
    "    w1 = abs(bottomRight[0] - bottomLeft[0])\n",
    "    w2 = abs(topRight[0] - topLeft[0])\n",
    "    h1 = abs(topRight[1] - bottomRight[1])\n",
    "    h2 = abs(topLeft[1] - bottomLeft[1])\n",
    "    maxWidth = max([w1, w2])\n",
    "    maxHeight = max([h1, h2])\n",
    "    \n",
    "    dst = np.float32([[0,0], [maxWidth-1,0], \n",
    "                      [maxWidth-1,maxHeight-1], [0,maxHeight-1]])\n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(rect, dst)\n",
    "    warped = cv2.warpPerspective(orig, M, (maxWidth, maxHeight))\n",
    "\n",
    "    # show the original and scanned images\n",
    "    print \"STEP 3: Apply perspective transform\"\n",
    "    cv2.imshow(\"Warped\", warped)\n",
    "    \n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "    \n",
    "    # convert the warped image to grayscale, then threshold it\n",
    "    # to give it that 'black and white' paper effect\n",
    "    warped = cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY)\n",
    "    warped = cv2.adaptiveThreshold(warped, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 21, 10)\n",
    "\n",
    "    # show the original and scanned images\n",
    "    print \"STEP 4: Apply Adaptive Threshold\"\n",
    "    cv2.imshow(\"Original\", orig)\n",
    "    cv2.imshow(\"Scanned\", warped)\n",
    "    cv2.imwrite('scannedImage.png', warped)\n",
    "    \n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    auto_scan_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "”33‘131101-é\"?5].9.\n",
      "Special Coupon\n"
     ]
    }
   ],
   "source": [
    "# OCR - Tesseract\n",
    "\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "def ocr_tesseract():\n",
    "    image_file = 'scannedImage.png'\n",
    "    im = Image.open(image_file)\n",
    "    # 윈도우의 경우 주석 해제\n",
    "#     pytesseract.pytesseract.tesseract_cmd = 'C:/Program Files (x86)/Tesseract-OCR/tesseract'\n",
    "    text = pytesseract.image_to_string(im)\n",
    "    im.show()\n",
    "\n",
    "    print text\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ocr_tesseract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"language\":\"en\",\"textAngle\":0.0,\"orientation\":\"Up\",\"regions\":[{\"boundingBox\":\"79,130,317,184\",\"lines\":[{\"boundingBox\":\"79,130,317,43\",\"words\":[{\"boundingBox\":\"79,130,144,41\",\"text\":\"Special\"},{\"boundingBox\":\"237,132,159,41\",\"text\":\"Coupon\"}]},{\"boundingBox\":\"151,286,174,12\",\"words\":[{\"boundingBox\":\"151,286,174,12\",\"text\":\"PARKSEUNGCHOL\"}]},{\"boundingBox\":\"178,303,120,11\",\"words\":[{\"boundingBox\":\"178,303,120,11\",\"text\":\"HAIRSTUOIO\"}]}]}]}\n",
      "\n",
      "Special Coupon\n",
      "PARKSEUNGCHOL\n",
      "HAIRSTUOIO\n"
     ]
    }
   ],
   "source": [
    "# OCR - Project Oxford by MS\n",
    "\n",
    "from PIL import Image\n",
    "import httplib, urllib, base64, json\n",
    "\n",
    "def print_text(json_data):\n",
    "    result = json.loads(json_data)\n",
    "    for l in result['regions']:\n",
    "        for w in l['lines']:\n",
    "            line = []\n",
    "            for r in w['words']:\n",
    "                line.append(r['text'])\n",
    "            print ' '.join(line)\n",
    "    return\n",
    "\n",
    "def ocr_project_oxford(headers, params, data):\n",
    "    conn = httplib.HTTPSConnection('api.projectoxford.ai')\n",
    "    conn.request(\"POST\", \"/vision/v1.0/ocr?%s\" % params, data, headers=headers)\n",
    "    response = conn.getresponse()\n",
    "    data = response.read()\n",
    "    print data + \"\\n\"\n",
    "    print_text(data)\n",
    "    conn.close()\n",
    "    return\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    headers = {\n",
    "        # Request headers\n",
    "        'Content-Type': 'application/octet-stream',\n",
    "        'Ocp-Apim-Subscription-Key': '', # project oxford 인증키 입력\n",
    "    }\n",
    "    params = urllib.urlencode({\n",
    "        # Request parameters\n",
    "        'language': 'unk',\n",
    "        'detectOrientation ': 'true',\n",
    "    })\n",
    "    data = open('scannedImage.png', 'rb').read()\n",
    "    \n",
    "    try:\n",
    "        image_file = 'scannedImage.png'\n",
    "        im = Image.open(image_file)\n",
    "        im.show()\n",
    "        ocr_project_oxford(headers, params, data)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OpenCV - 얼굴인식 구현하기 (1)\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def face_detection():\n",
    "    face_xml = 'haarcascades/haarcascade_frontalface_default.xml'\n",
    "    eye_xml = 'haarcascades/haarcascade_eye.xml'\n",
    "    face_cascade = cv2.CascadeClassifier(face_xml)\n",
    "    eye_cascade = cv2.CascadeClassifier(eye_xml)\n",
    "    \n",
    "    img = cv2.imread('images/people.jpg')\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img, (x,y), (x+w,y+h), (255,0,0), 2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(roi_color, (ex,ey), (ex+ew,ey+eh), (0,255,0), 2)\n",
    "    \n",
    "    cv2.imshow('result', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    face_detection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4311 -> 4836 / 5173 (0), 26596 -> 46322 / 679936 (0.741690479771), 0.892593606614 -> 0.933361144565\n",
      "0 4836 -> 5107 / 5173 (0), 46322 -> 50255 / 679936 (0.0849056603774), 0.933361144565 -> 0.955687772448\n",
      "1 5107 -> 5138 / 5173 (0), 50255 -> 50692 / 679936 (0.00869565217391), 0.955687772448 -> 0.958142512718\n",
      "images/text.jpg -> cropped_document.png\n"
     ]
    }
   ],
   "source": [
    "# (참고) OpenCV - 이미지에서 텍스트 영역만 찾아내기\n",
    "\n",
    "# 출처: http://www.danvk.org/2015/01/07/finding-blocks-of-text-in-an-image-using-python-opencv-and-numpy.html\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "from scipy.ndimage.filters import rank_filter\n",
    "\n",
    "\n",
    "def dilate(ary, N, iterations): \n",
    "    \"\"\"Dilate using an NxN '+' sign shape. ary is np.uint8.\"\"\"\n",
    "    kernel = np.zeros((N,N), dtype=np.uint8)\n",
    "    kernel[(N-1)/2,:] = 1\n",
    "    dilated_image = cv2.dilate(ary / 255, kernel, iterations=iterations)\n",
    "\n",
    "    kernel = np.zeros((N,N), dtype=np.uint8)\n",
    "    kernel[:,(N-1)/2] = 1\n",
    "    dilated_image = cv2.dilate(dilated_image, kernel, iterations=iterations)\n",
    "    return dilated_image\n",
    "\n",
    "\n",
    "def props_for_contours(contours, ary):\n",
    "    \"\"\"Calculate bounding box & the number of set pixels for each contour.\"\"\"\n",
    "    c_info = []\n",
    "    for c in contours:\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        c_im = np.zeros(ary.shape)\n",
    "        cv2.drawContours(c_im, [c], 0, 255, -1)\n",
    "        c_info.append({\n",
    "            'x1': x,\n",
    "            'y1': y,\n",
    "            'x2': x + w - 1,\n",
    "            'y2': y + h - 1,\n",
    "            'sum': np.sum(ary * (c_im > 0))/255\n",
    "        })\n",
    "    return c_info\n",
    "\n",
    "\n",
    "def union_crops(crop1, crop2):\n",
    "    \"\"\"Union two (x1, y1, x2, y2) rects.\"\"\"\n",
    "    x11, y11, x21, y21 = crop1\n",
    "    x12, y12, x22, y22 = crop2\n",
    "    return min(x11, x12), min(y11, y12), max(x21, x22), max(y21, y22)\n",
    "\n",
    "\n",
    "def intersect_crops(crop1, crop2):\n",
    "    x11, y11, x21, y21 = crop1\n",
    "    x12, y12, x22, y22 = crop2\n",
    "    return max(x11, x12), max(y11, y12), min(x21, x22), min(y21, y22)\n",
    "\n",
    "\n",
    "def crop_area(crop):\n",
    "    x1, y1, x2, y2 = crop\n",
    "    return max(0, x2 - x1) * max(0, y2 - y1)\n",
    "\n",
    "\n",
    "def find_border_components(contours, ary):\n",
    "    borders = []\n",
    "    area = ary.shape[0] * ary.shape[1]\n",
    "    for i, c in enumerate(contours):\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        if w * h > 0.5 * area:\n",
    "            borders.append((i, x, y, x + w - 1, y + h - 1))\n",
    "    return borders\n",
    "\n",
    "\n",
    "def angle_from_right(deg):\n",
    "    return min(deg % 90, 90 - (deg % 90))\n",
    "\n",
    "\n",
    "def remove_border(contour, ary):\n",
    "    \"\"\"Remove everything outside a border contour.\"\"\"\n",
    "    # Use a rotated rectangle (should be a good approximation of a border).\n",
    "    # If it's far from a right angle, it's probably two sides of a border and\n",
    "    # we should use the bounding box instead.\n",
    "    c_im = np.zeros(ary.shape)\n",
    "    r = cv2.minAreaRect(contour)\n",
    "    degs = r[2]\n",
    "    if angle_from_right(degs) <= 10.0:\n",
    "        box = cv2.cv.BoxPoints(r)\n",
    "        box = np.int0(box)\n",
    "        cv2.drawContours(c_im, [box], 0, 255, -1)\n",
    "        cv2.drawContours(c_im, [box], 0, 0, 4)\n",
    "    else:\n",
    "        x1, y1, x2, y2 = cv2.boundingRect(contour)\n",
    "        cv2.rectangle(c_im, (x1, y1), (x2, y2), 255, -1)\n",
    "        cv2.rectangle(c_im, (x1, y1), (x2, y2), 0, 4)\n",
    "\n",
    "    return np.minimum(c_im, ary)\n",
    "\n",
    "\n",
    "def find_components(edges, max_components=16):\n",
    "    \"\"\"Dilate the image until there are just a few connected components.\n",
    "    Returns contours for these components.\"\"\"\n",
    "    # Perform increasingly aggressive dilation until there are just a few\n",
    "    # connected components.\n",
    "    count = 21\n",
    "    dilation = 5\n",
    "    n = 1\n",
    "    while count > 16:\n",
    "        n += 1\n",
    "        dilated_image = dilate(edges, N=3, iterations=n)\n",
    "        contours, hierarchy = cv2.findContours(dilated_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        count = len(contours)\n",
    "    #print dilation\n",
    "    #Image.fromarray(edges).show()\n",
    "    #Image.fromarray(255 * dilated_image).show()\n",
    "    return contours\n",
    "\n",
    "\n",
    "def find_optimal_components_subset(contours, edges):\n",
    "    \"\"\"Find a crop which strikes a good balance of coverage/compactness.\n",
    "    Returns an (x1, y1, x2, y2) tuple.\n",
    "    \"\"\"\n",
    "    c_info = props_for_contours(contours, edges)\n",
    "    c_info.sort(key=lambda x: -x['sum'])\n",
    "    total = np.sum(edges) / 255\n",
    "    area = edges.shape[0] * edges.shape[1]\n",
    "\n",
    "    c = c_info[0]\n",
    "    del c_info[0]\n",
    "    this_crop = c['x1'], c['y1'], c['x2'], c['y2']\n",
    "    crop = this_crop\n",
    "    covered_sum = c['sum']\n",
    "\n",
    "    while covered_sum < total:\n",
    "        changed = False\n",
    "        recall = 1.0 * covered_sum / total\n",
    "        prec = 1 - 1.0 * crop_area(crop) / area\n",
    "        f1 = 2 * (prec * recall / (prec + recall))\n",
    "        #print '----'\n",
    "        for i, c in enumerate(c_info):\n",
    "            this_crop = c['x1'], c['y1'], c['x2'], c['y2']\n",
    "            new_crop = union_crops(crop, this_crop)\n",
    "            new_sum = covered_sum + c['sum']\n",
    "            new_recall = 1.0 * new_sum / total\n",
    "            new_prec = 1 - 1.0 * crop_area(new_crop) / area\n",
    "            new_f1 = 2 * new_prec * new_recall / (new_prec + new_recall)\n",
    "\n",
    "            # Add this crop if it improves f1 score,\n",
    "            # _or_ it adds 25% of the remaining pixels for <15% crop expansion.\n",
    "            # ^^^ very ad-hoc! make this smoother\n",
    "            remaining_frac = c['sum'] / (total - covered_sum)\n",
    "            new_area_frac = 1.0 * crop_area(new_crop) / crop_area(crop) - 1\n",
    "            if new_f1 > f1 or (\n",
    "                    remaining_frac > 0.25 and new_area_frac < 0.15):\n",
    "                print '%d %s -> %s / %s (%s), %s -> %s / %s (%s), %s -> %s' % (\n",
    "                        i, covered_sum, new_sum, total, remaining_frac,\n",
    "                        crop_area(crop), crop_area(new_crop), area, new_area_frac,\n",
    "                        f1, new_f1)\n",
    "                crop = new_crop\n",
    "                covered_sum = new_sum\n",
    "                del c_info[i]\n",
    "                changed = True\n",
    "                break\n",
    "\n",
    "        if not changed:\n",
    "            break\n",
    "\n",
    "    return crop\n",
    "\n",
    "\n",
    "def pad_crop(crop, contours, edges, border_contour, pad_px=15):\n",
    "    \"\"\"Slightly expand the crop to get full contours.\n",
    "    This will expand to include any contours it currently intersects, but will\n",
    "    not expand past a border.\n",
    "    \"\"\"\n",
    "    bx1, by1, bx2, by2 = 0, 0, edges.shape[0], edges.shape[1]\n",
    "    if border_contour is not None and len(border_contour) > 0:\n",
    "        c = props_for_contours([border_contour], edges)[0]\n",
    "        bx1, by1, bx2, by2 = c['x1'] + 5, c['y1'] + 5, c['x2'] - 5, c['y2'] - 5\n",
    "\n",
    "    def crop_in_border(crop):\n",
    "        x1, y1, x2, y2 = crop\n",
    "        x1 = max(x1 - pad_px, bx1)\n",
    "        y1 = max(y1 - pad_px, by1)\n",
    "        x2 = min(x2 + pad_px, bx2)\n",
    "        y2 = min(y2 + pad_px, by2)\n",
    "        return crop\n",
    "    \n",
    "    crop = crop_in_border(crop)\n",
    "\n",
    "    c_info = props_for_contours(contours, edges)\n",
    "    changed = False\n",
    "    for c in c_info:\n",
    "        this_crop = c['x1'], c['y1'], c['x2'], c['y2']\n",
    "        this_area = crop_area(this_crop)\n",
    "        int_area = crop_area(intersect_crops(crop, this_crop))\n",
    "        new_crop = crop_in_border(union_crops(crop, this_crop))\n",
    "        if 0 < int_area < this_area and crop != new_crop:\n",
    "            print '%s -> %s' % (str(crop), str(new_crop))\n",
    "            changed = True\n",
    "            crop = new_crop\n",
    "\n",
    "    if changed:\n",
    "        return pad_crop(crop, contours, edges, border_contour, pad_px)\n",
    "    else:\n",
    "        return crop\n",
    "\n",
    "\n",
    "def downscale_image(im, max_dim=2048):\n",
    "    \"\"\"Shrink im until its longest dimension is <= max_dim.\n",
    "    Returns new_image, scale (where scale <= 1).\n",
    "    \"\"\"\n",
    "    a, b = im.size\n",
    "    if max(a, b) <= max_dim:\n",
    "        return 1.0, im\n",
    "\n",
    "    scale = 1.0 * max_dim / max(a, b)\n",
    "    new_im = im.resize((int(a * scale), int(b * scale)), Image.ANTIALIAS)\n",
    "    return scale, new_im\n",
    "\n",
    "\n",
    "def process_image(path, out_path):\n",
    "    orig_im = Image.open(path)\n",
    "    scale, im = downscale_image(orig_im)\n",
    "\n",
    "    edges = cv2.Canny(np.asarray(im), 100, 200)\n",
    "\n",
    "    # TODO: dilate image _before_ finding a border. This is crazy sensitive!\n",
    "    contours, hierarchy = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    borders = find_border_components(contours, edges)\n",
    "    borders.sort(key=lambda (i, x1, y1, x2, y2): (x2 - x1) * (y2 - y1))\n",
    "\n",
    "    border_contour = None\n",
    "    if len(borders):\n",
    "        border_contour = contours[borders[0][0]]\n",
    "        edges = remove_border(border_contour, edges)\n",
    "\n",
    "    edges = 255 * (edges > 0).astype(np.uint8)\n",
    "\n",
    "    # Remove ~1px borders using a rank filter.\n",
    "    maxed_rows = rank_filter(edges, -4, size=(1, 20))\n",
    "    maxed_cols = rank_filter(edges, -4, size=(20, 1))\n",
    "    debordered = np.minimum(np.minimum(edges, maxed_rows), maxed_cols)\n",
    "    edges = debordered\n",
    "\n",
    "    contours = find_components(edges)\n",
    "    if len(contours) == 0:\n",
    "        print '%s -> (no text!)' % path\n",
    "        return\n",
    "\n",
    "    crop = find_optimal_components_subset(contours, edges)\n",
    "    crop = pad_crop(crop, contours, edges, border_contour)\n",
    "\n",
    "    crop = [int(x / scale) for x in crop]  # upscale to the original image size.\n",
    "    \n",
    "    # draw and show cropped rectangle area in the original image\n",
    "    draw = ImageDraw.Draw(im)\n",
    "    draw.rectangle(crop, outline='red')\n",
    "    im.show()\n",
    "    \n",
    "    text_im = orig_im.crop(crop)\n",
    "    text_im.save(out_path)\n",
    "    print '%s -> %s' % (path, out_path)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    path = 'images/text.jpg'\n",
    "    out_path = 'cropped_document.png'\n",
    "    try:\n",
    "        process_image(path, out_path)\n",
    "    except Exception as e:\n",
    "        print '%s %s' % (path, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
